{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "small_convnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "rwOe769ilnu5"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teymour-aldridge/NN/blob/master/computer_vision/boat_classifier/pytorch/convnet_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Isf4aWb0lOVx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initial setup"
      ]
    },
    {
      "metadata": {
        "id": "xLO3T_gTlVPf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Colab-related stuff"
      ]
    },
    {
      "metadata": {
        "id": "OeutAnNdvsu-",
        "colab_type": "code",
        "outputId": "1bcfad1f-b683-4d42-b23f-eb40cf542dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JmCtqJhAZE2z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## tensorboardX (tensorboard for PyTorch)"
      ]
    },
    {
      "metadata": {
        "id": "SMlZ349ShSPQ",
        "colab_type": "code",
        "outputId": "b24f109d-f78c-4ef6-9871-04f7b4b42458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.14.6)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (40.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y-YVN0LUZqfe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PyTorch installation  + set base directory + import matplotlib, os and shutil"
      ]
    },
    {
      "metadata": {
        "id": "GXXDmDqmxY_1",
        "colab_type": "code",
        "outputId": "489365c5-75a1-4499-f3c6-4ad69b7bd60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "# Install PyTorch\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m  HTTP error 403 while getting http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\u001b[0m\n",
            "\u001b[31m  Could not install requirement torch==0.4.1 from http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl because of error 403 Client Error: Forbidden for url: http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\u001b[0m\n",
            "\u001b[31mCould not install requirement torch==0.4.1 from http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl because of HTTP error 403 Client Error: Forbidden for url: http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl for URL http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lyxq3YeKi_Qb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "base_path = \"/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sz3N6qnL4HhI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Artificially enhance dataset"
      ]
    },
    {
      "metadata": {
        "id": "rBsXsVPm4NTn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes = ['buoy', 'cruise ship', 'ferry boat', 'freight boat', 'gondola', 'inflatable boat', 'kayak', 'paper boat', 'sailboat']\n",
        "\n",
        "for c in classes:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSadDDidlSeY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train-test split"
      ]
    },
    {
      "metadata": {
        "id": "AZZfhAUd2sxc",
        "colab_type": "code",
        "outputId": "238a50cd-b8a1-4b3c-c770-8131e3672678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Train/Test split\n",
        "# Class names (exactly what you'd expect)\n",
        "classes = ['buoy', 'cruise ship', 'ferry boat', 'freight boat', 'gondola', 'inflatable boat', 'kayak', 'paper boat', 'sailboat']\n",
        "# Get the number of files in each directory\n",
        "file_lengths = [len(os.listdir(\"/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data/\" + c)) for c in classes]\n",
        "# For each class\n",
        "for c in classes:\n",
        "  files = os.listdir(os.path.join(base_path, c)) # Get all files\n",
        "  for i in range(len(files) // 5): # Get 20% of the files\n",
        "    src = os.path.join(base_path, c, files[i])\n",
        "    dest = os.path.abspath(os.path.join(base_path, 'test', c))\n",
        "    if not os.path.exists(dest):\n",
        "      os.mkdir(dest)\n",
        "    shutil.move(src, dest)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Train/Test split\\n# Class names (exactly what you\\'d expect)\\nclasses = [\\'buoy\\', \\'cruise ship\\', \\'ferry boat\\', \\'freight boat\\', \\'gondola\\', \\'inflatable boat\\', \\'kayak\\', \\'paper boat\\', \\'sailboat\\']\\n# Get the number of files in each directory\\nfile_lengths = [len(os.listdir(\"/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data/\" + c)) for c in classes]\\n# For each class\\nfor c in classes:\\n  files = os.listdir(os.path.join(base_path, c)) # Get all files\\n  for i in range(len(files) // 5): # Get 20% of the files\\n    src = os.path.join(base_path, c, files[i])\\n    dest = os.path.abspath(os.path.join(base_path, \\'test\\', c))\\n    if not os.path.exists(dest):\\n      os.mkdir(dest)\\n    shutil.move(src, dest)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "JABwjZOvIzfK",
        "colab_type": "code",
        "outputId": "83ece722-ed88-4fe1-bddb-880f8084dec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_path = os.path.join(base_path, 'train')\n",
        "test_path = os.path.join(base_path, 'test')\n",
        "classes = os.listdir(train_path)\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['inflatable boat', 'gondola', 'sailboat', 'freight boat', 'ferry boat', 'paper boat', 'kayak', 'cruise ship', 'buoy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PtPI5HE0lYqn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate an index for the dataset"
      ]
    },
    {
      "metadata": {
        "id": "jr73exjCpMiR",
        "colab_type": "code",
        "outputId": "09a7f9d7-fe34-429f-ae06-8b4020de326c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data_class = 'sailboat'\n",
        "os.path.join(train_path, data_class) + '/*.jpg'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data/train/sailboat/*.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "DKoAqzteJuXK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "train_index = pd.DataFrame(columns=['class', 'path'])\n",
        "test_index = pd.DataFrame(columns=['class', 'path'])\n",
        "\n",
        "for i, data_class in enumerate(os.listdir(train_path)): # For each class (there are 9)\n",
        "  \n",
        "  for file in glob.glob(os.path.join(train_path, data_class) + '/*.jpg'): # Get all JPEG files\n",
        "\n",
        "    train_index = train_index.append({\n",
        "        'class': i,\n",
        "        'path': os.path.join(train_path, data_class, file)\n",
        "    }, ignore_index = True)\n",
        "    \n",
        "    \n",
        "for i, data_class in enumerate(os.listdir(test_path)): # For each class (there are 9)\n",
        "  \n",
        "  for file in glob.glob(os.path.join(test_path, data_class) + '/*.jpg'): # Get all JPEG files\n",
        "\n",
        "    test_index = test_index.append({\n",
        "        'class': i,\n",
        "        'path': os.path.join(test_path, data_class, file)\n",
        "    }, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwOe769ilnu5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PIL error fixing\n",
        "If *VERSION: 4.0.0* is printed then restart the runtime, and run it again (normally fixes the problem) as scikit-image requires a version of PIL (Python Imaging Library) greater than 4.1.1 (I think)."
      ]
    },
    {
      "metadata": {
        "id": "DxutzZGslqyq",
        "colab_type": "code",
        "outputId": "c8cdb8aa-963f-48e8-c78c-e32db007a4e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall -y Pillow\n",
        "# install the new one\n",
        "!pip install Pillow==5.3.0\n",
        "# import the new one\n",
        "import PIL\n",
        "print(\"VERSION:\", PIL.PILLOW_VERSION)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Pillow-5.3.0:\n",
            "  Successfully uninstalled Pillow-5.3.0\n",
            "Collecting Pillow==5.3.0\n",
            "  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.46 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "Successfully installed Pillow-5.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "VERSION: 5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FWNafAqklc3J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define dataset"
      ]
    },
    {
      "metadata": {
        "id": "TdpwI4xWxtrR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.utils import shuffle\n",
        "from PIL import Image\n",
        "\n",
        "\"\"\"\n",
        "  _____        _                 _   \n",
        " |  __ \\      | |               | |  \n",
        " | |  | | __ _| |_ __ _ ___  ___| |_ \n",
        " | |  | |/ _` | __/ _` / __|/ _ \\ __|\n",
        " | |__| | (_| | || (_| \\__ \\  __/ |_ \n",
        " |_____/ \\__,_|\\__\\__,_|___/\\___|\\__|\n",
        " (Dataset class, allows for an index to be passed.)                                   \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class IndexedImageDataset(Dataset):\n",
        "    def __init__(self, index, device, transform=None):\n",
        "        \"\"\"\n",
        "        Initializes an IndexedImageDataset, which reads an index from a pandas dataframe, and acts as a database wrapper.\n",
        "        :param index: A pandas dataframe storing with a list of classes and their respective files.\n",
        "        :param transform: A function, to be applied to the image (any function will do).\n",
        "        \"\"\"\n",
        "        assert isinstance(index, pd.DataFrame)  # Check if the \n",
        "        self.index = shuffle(index)\n",
        "        self.transform = transform\n",
        "        self.device = device\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index.index)  # Return the length of the dataset\n",
        "\n",
        "    def __getitem__(self, n):\n",
        "        x, y = self.index['path'].iloc[n], self.index['class'].iloc[n]  # Get x and y values for the neural network\n",
        "        x = Image.open(x)\n",
        "        x.show()\n",
        "        if self.transform:\n",
        "          x = self.transform(x)\n",
        "        x.double()\n",
        "        return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtVFQDlESf3q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_image_dataset=IndexedImageDataset(train_index, device,\n",
        "                                       transform=transforms.Compose([\n",
        "                                           transforms.Resize((512, 512)),\n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize((0.611, 0.611, 0.611), (0.14, 0.14, 0.14)),\n",
        "                                       ]))\n",
        "train_image_loader = DataLoader(\n",
        "    train_image_dataset,\n",
        "    batch_size=4,\n",
        "    num_workers=1,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-1yyqShrdDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Normalize dataset\n",
        "Note that this assumes the data is normally distributed (I haven't checked)."
      ]
    },
    {
      "metadata": {
        "id": "jVC-kybWSz8Q",
        "colab_type": "code",
        "outputId": "e6b74286-264a-4e4c-a1d4-a6c6241f21a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Commented out because it does not make sense to perform the same calculations many times\n",
        "\"\"\"mean = 0.\n",
        "std = 0.\n",
        "nb_samples = 0.\n",
        "for data, _ in train_image_loader:\n",
        "    batch_samples = data.size(0)\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    mean += data.mean(2).sum(0)\n",
        "    std += data.std(2).sum(0)\n",
        "    nb_samples += batch_samples\n",
        "\n",
        "mean /= nb_samples\n",
        "std /= nb_samples\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mean = 0.\\nstd = 0.\\nnb_samples = 0.\\nfor data, _ in train_image_loader:\\n    batch_samples = data.size(0)\\n    data = data.view(batch_samples, data.size(1), -1)\\n    mean += data.mean(2).sum(0)\\n    std += data.std(2).sum(0)\\n    nb_samples += batch_samples\\n\\nmean /= nb_samples\\nstd /= nb_samples'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "metadata": {
        "id": "UI5xMYC-Idan",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print([mean[x].mean() for x in range(3)])\n",
        "# print([std[x].mean() for x in range(3)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vp83UHM2kPtT",
        "colab_type": "code",
        "outputId": "1249118f-0181-4aa8-cb93-7e053da2ab2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-c78c78209055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_image_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "dqloHbdMliYp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "DEZNEj6Ox5Lj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BoatNetwork(nn.Module):\n",
        "  def __init__(self, num_classes=9):\n",
        "    super(BoatNetwork, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=2, padding=1).double()\n",
        "    self.conv2 = nn.Conv2d(16, 32, kernel_size=2, padding=1).double()\n",
        "    self.conv3 = nn.Conv2d(32, 64, kernel_size=2, padding=1).double()\n",
        "    self.fc = nn.Linear(64*64*64, 64)\n",
        "    self.fc2 = nn.Linear(64, num_classes)\n",
        "  def forward(self, x):\n",
        "    x = x.to(device)\n",
        "    x = x.double()\n",
        "    x = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "    x = F.max_pool2d(torch.tanh(self.conv2(x)), 2)\n",
        "    x = F.max_pool2d(torch.tanh(self.conv3(x)), 2)\n",
        "    x = x.reshape(x.size(0), -1).float()\n",
        "    x = torch.tanh(self.fc(x))\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yb4kn9ee0xI4",
        "colab_type": "code",
        "outputId": "b99cf48a-ad44-4e9c-92e8-aa6322dcba92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "model = BoatNetwork()\n",
        "model.to(device)\n",
        "learning_rate = 1e-2\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn.to(device)\n",
        "n_epochs = 100\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BoatNetwork(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
              "  (fc): Linear(in_features=262144, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "metadata": {
        "id": "ZzydsjhFiYsA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorboardX import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "writer.add_scalar('data/loss', 12, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kZreC_zW0zcI",
        "colab_type": "code",
        "outputId": "097744f6-ff06-413d-fd30-68eff7454823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "loop_count_exists = os.path.isfile(os.path.join(base_path, 'EPOCH_COUNT'))\n",
        "if loop_count_exists: # Resume training from earlier save\n",
        "  with open(os.path.join(base_path, 'EPOCH_COUNT')) as epoch_count:\n",
        "    epoch_number = int(epoch_count.read())\n",
        "  model.load_state_dict(torch.load(os.path.join(base_path, 'model_weights.pt')))\n",
        "else:\n",
        "  epoch_number = 0 # Start from epoch 0\n",
        "for epoch in range(epoch_number, n_epochs):\n",
        "  i=0\n",
        "  for imgs, labels in train_image_loader:\n",
        "    imgs.to(device)\n",
        "    labels.to(device)\n",
        "    outputs = model(imgs)\n",
        "    outputs.to(device)\n",
        "    loss = loss_fn(outputs, labels.cuda())\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    writer.add_scalar('data/loss', loss, epoch)\n",
        "  \n",
        "  print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "  torch.save(model.state_dict(), os.path.join(base_path, 'model_weights.pt'))\n",
        "  with open(os.path.join(base_path, 'EPOCH_COUNT'), 'w') as epoch_count:\n",
        "    epoch_count.write(str(epoch))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27, Loss: 0.001406\n",
            "Epoch: 28, Loss: 0.001229\n",
            "Epoch: 29, Loss: 0.001112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "adgr2GJxKxup",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}