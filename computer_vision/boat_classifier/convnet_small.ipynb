{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_neural_network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teymour-aldridge/NN/blob/master/computer_vision/boat_classifier/convnet_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Isf4aWb0lOVx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initial setup"
      ]
    },
    {
      "metadata": {
        "id": "xLO3T_gTlVPf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Colab-related stuff"
      ]
    },
    {
      "metadata": {
        "id": "OeutAnNdvsu-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vGMQNntYhAsg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = '/tmp/log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SMlZ349ShSPQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GXXDmDqmxY_1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install PyTorch\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lyxq3YeKi_Qb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "base_path = \"/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sz3N6qnL4HhI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Artificially enhance dataset"
      ]
    },
    {
      "metadata": {
        "id": "rBsXsVPm4NTn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes = ['buoy', 'cruise ship', 'ferry boat', 'freight boat', 'gondola', 'inflatable boat', 'kayak', 'paper boat', 'sailboat']\n",
        "\n",
        "for c in classes:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSadDDidlSeY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train-test split"
      ]
    },
    {
      "metadata": {
        "id": "AZZfhAUd2sxc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Train/Test split\n",
        "# Class names (exactly what you'd expect)\n",
        "classes = ['buoy', 'cruise ship', 'ferry boat', 'freight boat', 'gondola', 'inflatable boat', 'kayak', 'paper boat', 'sailboat']\n",
        "# Get the number of files in each directory\n",
        "file_lengths = [len(os.listdir(\"/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data/\" + c)) for c in classes]\n",
        "# For each class\n",
        "for c in classes:\n",
        "  files = os.listdir(os.path.join(base_path, c)) # Get all files\n",
        "  for i in range(len(files) // 5): # Get 20% of the files\n",
        "    src = os.path.join(base_path, c, files[i])\n",
        "    dest = os.path.abspath(os.path.join(base_path, 'test', c))\n",
        "    if not os.path.exists(dest):\n",
        "      os.mkdir(dest)\n",
        "    shutil.move(src, dest)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JABwjZOvIzfK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_path = os.path.join(base_path, 'train')\n",
        "test_path = os.path.join(base_path, 'test')\n",
        "classes = os.listdir(train_path)\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PtPI5HE0lYqn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate indices"
      ]
    },
    {
      "metadata": {
        "id": "jr73exjCpMiR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_class = 'sailboat'\n",
        "os.path.join(train_path, data_class) + '/*.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DKoAqzteJuXK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "train_index = pd.DataFrame(columns=['class', 'path'])\n",
        "test_index = pd.DataFrame(columns=['class', 'path'])\n",
        "\n",
        "for i, data_class in enumerate(os.listdir(train_path)): # For each class (there are 9)\n",
        "  \n",
        "  for file in glob.glob(os.path.join(train_path, data_class) + '/*.jpg'): # Get all JPEG files\n",
        "\n",
        "    train_index = train_index.append({\n",
        "        'class': i,\n",
        "        'path': os.path.join(train_path, data_class, file)\n",
        "    }, ignore_index = True)\n",
        "    \n",
        "    \n",
        "for i, data_class in enumerate(os.listdir(test_path)): # For each class (there are 9)\n",
        "  \n",
        "  for file in glob.glob(os.path.join(test_path, data_class) + '/*.jpg'): # Get all JPEG files\n",
        "\n",
        "    test_index = test_index.append({\n",
        "        'class': i,\n",
        "        'path': os.path.join(test_path, data_class, file)\n",
        "    }, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwOe769ilnu5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PIL error fixing"
      ]
    },
    {
      "metadata": {
        "id": "DxutzZGslqyq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall -y Pillow\n",
        "# install the new one\n",
        "!pip install Pillow==5.3.0\n",
        "# import the new one\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FWNafAqklc3J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define dataset"
      ]
    },
    {
      "metadata": {
        "id": "TdpwI4xWxtrR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "\"\"\"\n",
        "  _____        _                 _   \n",
        " |  __ \\      | |               | |  \n",
        " | |  | | __ _| |_ __ _ ___  ___| |_ \n",
        " | |  | |/ _` | __/ _` / __|/ _ \\ __|\n",
        " | |__| | (_| | || (_| \\__ \\  __/ |_ \n",
        " |_____/ \\__,_|\\__\\__,_|___/\\___|\\__|\n",
        " (Dataset class, allows for an index to be passed.)                                   \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class IndexedImageDataset(Dataset):\n",
        "    def __init__(self, index, transform=None):\n",
        "        \"\"\"\n",
        "        Initializes an IndexedImageDataset, which reads an index from a pandas dataframe, and acts as a database wrapper.\n",
        "        :param index: A pandas dataframe storing with a list of classes and their respective files.\n",
        "        :param transform: A function, to be applied to the image (any function will do).\n",
        "        \"\"\"\n",
        "        assert isinstance(index, pd.DataFrame)  # Check if the \n",
        "        self.index = index\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index.index)  # Return the length of the dataset\n",
        "\n",
        "    def __getitem__(self, n):\n",
        "        x, y = self.index['path'].iloc[n], self.index['class'].iloc[n]  # Get x and y values for the neural network\n",
        "        x = io.imread(x)\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  _______                   __                         \n",
        " |__   __|                 / _|                        \n",
        "    | |_ __ __ _ _ __  ___| |_ ___  _ __ _ __ ___  ___ \n",
        "    | | '__/ _` | '_ \\/ __|  _/ _ \\| '__| '_ ` _ \\/ __|\n",
        "    | | | | (_| | | | \\__ \\ || (_) | |  | | | | | \\__ \\\n",
        "    |_|_|  \\__,_|_| |_|___/_| \\___/|_|  |_| |_| |_|___/\n",
        "    (Transform images)                                                  \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class Rescale(object):\n",
        "    def __init__(self, output_size):\n",
        "        \"\"\"\n",
        "        Rescales images down to the specified height. \n",
        "        :param output_size: The size of the image to be outputted.\n",
        "        \"\"\"\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        Resizes an image to the desired dimensions. \n",
        "        :param x: the image to be resized\n",
        "        \"\"\"\n",
        "        h, w = x.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        return transform.resize(x, (new_h, new_w))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtVFQDlESf3q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_image_dataset=IndexedImageDataset(train_index,\n",
        "                                       transform = transforms.Compose( # Join multiple transforms together.\n",
        "                                           [\n",
        "                                               Rescale(output_size = (512, 512)), # Downsize all images to 512 x 512 \n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize((0.5148, 0.5148, 0.5148), (0.1871, 0.1871, 0.1871))\n",
        "                                           ]\n",
        "                                       ))\n",
        "train_image_loader = DataLoader(\n",
        "    train_image_dataset,\n",
        "    batch_size=4,\n",
        "    num_workers=1,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-1yyqShrdDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Normalize dataset\n",
        "Note that this assumes the data is normally distributed (I haven't checked)."
      ]
    },
    {
      "metadata": {
        "id": "jVC-kybWSz8Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"mean = 0.\n",
        "std = 0.\n",
        "nb_samples = 0.\n",
        "for data, _ in train_image_loader:\n",
        "    batch_samples = data.size(0)\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    mean += data.mean(2).sum(0)\n",
        "    std += data.std(2).sum(0)\n",
        "    nb_samples += batch_samples\n",
        "\n",
        "mean /= nb_samples\n",
        "std /= nb_samples\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vp83UHM2kPtT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_image_dataset[0][0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dqloHbdMliYp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "DEZNEj6Ox5Lj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BoatNetwork(nn.Module):\n",
        "  def __init__(self, num_classes=9):\n",
        "    super(BoatNetwork, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=2, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, kernel_size=2, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, kernel_size=2, padding=1)\n",
        "    self.fc = nn.Linear(64*64*64, 64)\n",
        "    self.fc2 = nn.Linear(64, num_classes)\n",
        "  def forward(self, x):\n",
        "    x = x.double()\n",
        "    x = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "    x = F.max_pool2d(torch.tanh(self.conv2(x)), 2)\n",
        "    x = F.max_pool2d(torch.tanh(self.conv3(x)), 2)\n",
        "    x = x.reshape(x.size(0), -1)\n",
        "    x = torch.tanh(self.fc(x))\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yb4kn9ee0xI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = BoatNetwork().double()\n",
        "learning_rate = 1e-2\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZzydsjhFiYsA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorboardX import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "writer.add_scalar('data/loss', 12, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kZreC_zW0zcI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loop_count_exists = os.path.isfile(os.path.join(base_path, 'EPOCH_COUNT'))\n",
        "if loop_count_exists: # Resume training\n",
        "  with open(os.path.join(base_path, 'EPOCH_COUNT')) as epoch_count:\n",
        "    epoch_number = int(epoch_count.read())\n",
        "else:\n",
        "  epoch_number = 0 # Start from epoch 0\n",
        "for epoch in range(epoch_number, n_epochs):\n",
        "  \n",
        "  for imgs, labels in train_image_loader:\n",
        "    outputs = model(imgs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    writer.add_scalar('data/loss', loss, epoch)\n",
        "  \n",
        "  print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "  torch.save(model.state_dict(), os.path.join(base_path, 'model_weights.pt'))\n",
        "  with open(os.path.join(base_dir, 'EPOCH_COUNT'), 'w') as epoch_count:\n",
        "    epoch_count.write(str(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1-58Z_8vBYqm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_path = \"/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9gy4tZZd1LG-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SOU_l6cT35aT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUg3hVUb4SLw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}