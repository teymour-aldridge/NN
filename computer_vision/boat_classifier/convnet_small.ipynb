{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_neural_network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teymour-aldridge/NN/blob/master/computer_vision/boat_classifier/convnet_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Isf4aWb0lOVx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initial setup"
      ]
    },
    {
      "metadata": {
        "id": "xLO3T_gTlVPf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Colab-related stuff"
      ]
    },
    {
      "metadata": {
        "id": "OeutAnNdvsu-",
        "colab_type": "code",
        "outputId": "d389b6cc-95cb-4156-eee7-272cb8e1dd9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vGMQNntYhAsg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5b00aa08-377c-4ba2-8a26-9ec79388d422"
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = '/tmp/log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-23 19:22:29--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.201.75.180, 52.203.66.95, 52.202.60.111, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.201.75.180|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  33%[=====>              ]   1.74M  8.34MB/s               \rngrok-stable-linux- 100%[===================>]   5.11M  20.7MB/s    in 0.2s    \n",
            "\n",
            "2018-12-23 19:22:29 (20.7 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "http://c24a3648.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SMlZ349ShSPQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "8e4c4ef4-eb44-40cf-f122-762d8e357903"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/10/0cc87d34b4a02109bee5f7b9bd9c95524fbb540311f6fbcc3758591a3f3a/tensorboardX-1.5-py2.py3-none-any.whl (112kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.14.6)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (40.6.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GXXDmDqmxY_1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install PyTorch\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lyxq3YeKi_Qb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "base_path = \"/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSadDDidlSeY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train-test split"
      ]
    },
    {
      "metadata": {
        "id": "AZZfhAUd2sxc",
        "colab_type": "code",
        "outputId": "26d9f66c-6b64-4e5b-db4d-eaa8486bfe17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Train/Test split\n",
        "# Class names (exactly what you'd expect)\n",
        "classes = ['buoy', 'cruise ship', 'ferry boat', 'freight boat', 'gondola', 'inflatable boat', 'kayak', 'paper boat', 'sailboat']\n",
        "# Get the number of files in each directory\n",
        "file_lengths = [len(os.listdir(\"/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data/\" + c)) for c in classes]\n",
        "# For each class\n",
        "for c in classes:\n",
        "  files = os.listdir(os.path.join(base_path, c)) # Get all files\n",
        "  for i in range(len(files) // 5): # Get 20% of the files\n",
        "    src = os.path.join(base_path, c, files[i])\n",
        "    dest = os.path.abspath(os.path.join(base_path, 'test', c))\n",
        "    if not os.path.exists(dest):\n",
        "      os.mkdir(dest)\n",
        "    shutil.move(src, dest)\n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Train/Test split\\n# Class names (exactly what you\\'d expect)\\nclasses = [\\'buoy\\', \\'cruise ship\\', \\'ferry boat\\', \\'freight boat\\', \\'gondola\\', \\'inflatable boat\\', \\'kayak\\', \\'paper boat\\', \\'sailboat\\']\\n# Get the number of files in each directory\\nfile_lengths = [len(os.listdir(\"/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data/\" + c)) for c in classes]\\n# For each class\\nfor c in classes:\\n  files = os.listdir(os.path.join(base_path, c)) # Get all files\\n  for i in range(len(files) // 5): # Get 20% of the files\\n    src = os.path.join(base_path, c, files[i])\\n    dest = os.path.abspath(os.path.join(base_path, \\'test\\', c))\\n    if not os.path.exists(dest):\\n      os.mkdir(dest)\\n    shutil.move(src, dest)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "JABwjZOvIzfK",
        "colab_type": "code",
        "outputId": "823d6314-e8db-4c52-d995-946325ab1dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_path = os.path.join(base_path, 'train')\n",
        "test_path = os.path.join(base_path, 'test')\n",
        "classes = os.listdir(train_path)\n",
        "print(classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['inflatable boat', 'gondola', 'sailboat', 'freight boat', 'ferry boat', 'paper boat', 'kayak', 'cruise ship', 'buoy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PtPI5HE0lYqn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate indices"
      ]
    },
    {
      "metadata": {
        "id": "jr73exjCpMiR",
        "colab_type": "code",
        "outputId": "2123d9eb-453e-41e0-c47a-143b0b91b79b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data_class = 'sailboat'\n",
        "os.path.join(train_path, data_class) + '/*.jpg'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data/train/sailboat/*.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "DKoAqzteJuXK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "train_index = pd.DataFrame(columns=['class', 'path'])\n",
        "test_index = pd.DataFrame(columns=['class', 'path'])\n",
        "\n",
        "for i, data_class in enumerate(os.listdir(train_path)): # For each class (there are 9)\n",
        "  \n",
        "  for file in glob.glob(os.path.join(train_path, data_class) + '/*.jpg'): # Get all JPEG files\n",
        "\n",
        "    train_index = train_index.append({\n",
        "        'class': i,\n",
        "        'path': os.path.join(train_path, data_class, file)\n",
        "    }, ignore_index = True)\n",
        "    \n",
        "    \n",
        "for i, data_class in enumerate(os.listdir(test_path)): # For each class (there are 9)\n",
        "  \n",
        "  for file in glob.glob(os.path.join(test_path, data_class) + '/*.jpg'): # Get all JPEG files\n",
        "\n",
        "    test_index = test_index.append({\n",
        "        'class': i,\n",
        "        'path': os.path.join(test_path, data_class, file)\n",
        "    }, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwOe769ilnu5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PIL error fixing"
      ]
    },
    {
      "metadata": {
        "id": "DxutzZGslqyq",
        "colab_type": "code",
        "outputId": "510295a5-aaf1-4a19-efa9-5963f8c82653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall -y Pillow\n",
        "# install the new one\n",
        "!pip install Pillow==5.3.0\n",
        "# import the new one\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Pillow-5.3.0:\n",
            "  Successfully uninstalled Pillow-5.3.0\n",
            "Collecting Pillow==5.3.0\n",
            "  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: Pillow\n",
            "Successfully installed Pillow-5.3.0\n",
            "5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FWNafAqklc3J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define dataset"
      ]
    },
    {
      "metadata": {
        "id": "TdpwI4xWxtrR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "\"\"\"\n",
        "  _____        _                 _   \n",
        " |  __ \\      | |               | |  \n",
        " | |  | | __ _| |_ __ _ ___  ___| |_ \n",
        " | |  | |/ _` | __/ _` / __|/ _ \\ __|\n",
        " | |__| | (_| | || (_| \\__ \\  __/ |_ \n",
        " |_____/ \\__,_|\\__\\__,_|___/\\___|\\__|\n",
        " (Dataset class, allows for an index to be passed.)                                   \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class IndexedImageDataset(Dataset):\n",
        "    def __init__(self, index, transform=None):\n",
        "        \"\"\"\n",
        "        Initializes an IndexedImageDataset, which reads an index from a pandas dataframe, and acts as a database wrapper.\n",
        "        :param index: A pandas dataframe storing with a list of classes and their respective files.\n",
        "        :param transform: A function, to be applied to the image (any function will do).\n",
        "        \"\"\"\n",
        "        assert isinstance(index, pd.DataFrame)  # Check if the \n",
        "        self.index = index\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index.index)  # Return the length of the dataset\n",
        "\n",
        "    def __getitem__(self, n):\n",
        "        x, y = self.index['path'].iloc[n], self.index['class'].iloc[n]  # Get x and y values for the neural network\n",
        "        x = io.imread(x)\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  _______                   __                         \n",
        " |__   __|                 / _|                        \n",
        "    | |_ __ __ _ _ __  ___| |_ ___  _ __ _ __ ___  ___ \n",
        "    | | '__/ _` | '_ \\/ __|  _/ _ \\| '__| '_ ` _ \\/ __|\n",
        "    | | | | (_| | | | \\__ \\ || (_) | |  | | | | | \\__ \\\n",
        "    |_|_|  \\__,_|_| |_|___/_| \\___/|_|  |_| |_| |_|___/\n",
        "    (Transform images)                                                  \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class Rescale(object):\n",
        "    def __init__(self, output_size):\n",
        "        \"\"\"\n",
        "        Rescales images down to the specified height. \n",
        "        :param output_size: The size of the image to be outputted.\n",
        "        \"\"\"\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        Resizes an image to the desired dimensions. \n",
        "        :param x: the image to be resized\n",
        "        \"\"\"\n",
        "        h, w = x.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        return transform.resize(x, (new_h, new_w))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtVFQDlESf3q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_image_dataset=IndexedImageDataset(train_index,\n",
        "                                       transform = transforms.Compose( # Join multiple transforms together.\n",
        "                                           [\n",
        "                                               Rescale(output_size = (512, 512)), # Downsize all images to 512 x 512 \n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize((0.5148, 0.5148, 0.5148), (0.1871, 0.1871, 0.1871))\n",
        "                                           ]\n",
        "                                       ))\n",
        "train_image_loader = DataLoader(\n",
        "    train_image_dataset,\n",
        "    batch_size=4,\n",
        "    num_workers=1,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-1yyqShrdDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Normalize dataset\n",
        "Note that this assumes the data is normally distributed (I haven't checked)."
      ]
    },
    {
      "metadata": {
        "id": "jVC-kybWSz8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e8eb73c3-cb4a-4e8d-8d95-399b06b63de7"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"mean = 0.\n",
        "std = 0.\n",
        "nb_samples = 0.\n",
        "for data, _ in train_image_loader:\n",
        "    batch_samples = data.size(0)\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    mean += data.mean(2).sum(0)\n",
        "    std += data.std(2).sum(0)\n",
        "    nb_samples += batch_samples\n",
        "\n",
        "mean /= nb_samples\n",
        "std /= nb_samples\"\"\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mean = 0.\\nstd = 0.\\nnb_samples = 0.\\nfor data, _ in train_image_loader:\\n    batch_samples = data.size(0)\\n    data = data.view(batch_samples, data.size(1), -1)\\n    mean += data.mean(2).sum(0)\\n    std += data.std(2).sum(0)\\n    nb_samples += batch_samples\\n\\nmean /= nb_samples\\nstd /= nb_samples'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "Vp83UHM2kPtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "5a6ab460-22c1-4304-93fe-ab2510eca680"
      },
      "cell_type": "code",
      "source": [
        "train_image_dataset[0][0].shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 512, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "dqloHbdMliYp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "DEZNEj6Ox5Lj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BoatNetwork(nn.Module):\n",
        "  def __init__(self, num_classes=9):\n",
        "    super(BoatNetwork, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=2, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, kernel_size=2, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, kernel_size=2, padding=1)\n",
        "    self.fc = nn.Linear(64*64*64, 64)\n",
        "    self.fc2 = nn.Linear(64, num_classes)\n",
        "  def forward(self, x):\n",
        "    x = x.double()\n",
        "    x = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "    x = F.max_pool2d(torch.tanh(self.conv2(x)), 2)\n",
        "    x = F.max_pool2d(torch.tanh(self.conv3(x)), 2)\n",
        "    x = x.reshape(x.size(0), -1)\n",
        "    x = torch.tanh(self.fc(x))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yb4kn9ee0xI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = BoatNetwork().double()\n",
        "learning_rate = 1e-2\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZzydsjhFiYsA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorboardX import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kZreC_zW0zcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3a9d96c5-0a1a-4a27-e7c1-9459030bcb45"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "  \n",
        "  for imgs, labels in train_image_loader:\n",
        "    outputs = model(imgs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    writer.add_scalar('data/loss', loss, epoch)\n",
        "  \n",
        "  print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1-58Z_8vBYqm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_path = \"/content/gdrive/My Drive/Computing/ML/Computer Vision/Boat Classification/data\"\n",
        "torch.save(model.state_dict(), os.path.join(base_path, 'model_weights.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9gy4tZZd1LG-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SOU_l6cT35aT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUg3hVUb4SLw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}